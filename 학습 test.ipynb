{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import gym\n",
    "import stable_baselines3\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO,DQN,A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\user\\Desktop\\123244\\binance_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stablebaselineEnv(gym.Env):\n",
    "    def __init__(self, df, full_window_size, test_window_size, usdt_balance, btc_size=0, leverage=1): \n",
    "        super(stablebaselineEnv, self).__init__()\n",
    "        self.slice_df, self.obs_df, self.train_df = stablebaselineEnv.generate_random_data_slice(df, full_window_size, test_window_size) # 랜덤 위치로 slice된 차트 데이터 초기화\n",
    "        self.action_space = spaces.Discrete(4)  # 0: Long, 1: Short, 2: Close, 3: Hold\n",
    "        self.current_step = self.slice_df.tail(1)\n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"chart_data\": spaces.Box(low=0, high=np.inf, shape=(len(self.current_step.columns),), dtype=np.float32), # 차트 데이터\n",
    "            \"position\": spaces.Discrete(3),  # 포지션 {0:Long, 1:Short, 2:None}\n",
    "            \"action\": spaces.Discrete(4),  # 액션 {0:Long, 1:Short, 2:Close, 3:Hold}\n",
    "            \"current_price\": spaces.Box(low=0, high=np.inf, shape=(), dtype=np.float32),  # 현재 가격\n",
    "            \"avg_price\": spaces.Box(low=0, high=np.inf, shape=(), dtype=np.float32),  # 평균 진입 가격\n",
    "            \"pnl\": spaces.Box(low=-np.inf, high=np.inf, shape=(), dtype=np.float32),  # 미실현 손익\n",
    "            \"total_pnl\": spaces.Box(low=-np.inf, high=np.inf, shape=(), dtype=np.float32),  # 누적 손익\n",
    "            \"usdt_balance\": spaces.Box(low=0, high=np.inf, shape=(), dtype=np.float32),  # USDT 잔고\n",
    "            \"size\": spaces.Box(low=0, high=np.inf, shape=(), dtype=np.float32),  # 포지션 수량\n",
    "            \"margin\": spaces.Box(low=0, high=np.inf, shape=(), dtype=np.float32),  # 사용 중인 마진\n",
    "            \"total_balance\": spaces.Box(low=0, high=np.inf, shape=(), dtype=np.float32)  # 총 자산\n",
    "        })\n",
    "        self.full_window_size = full_window_size\n",
    "        self.test_window_size = test_window_size\n",
    "        self.start_step = self.full_window_size\n",
    "        self.window_size = self.full_window_size\n",
    "        self.current_price = 0\n",
    "\n",
    "\n",
    "        # reset 미포함\n",
    "        self.initial_usdt_balance = usdt_balance # 초기 usdt 잔고\n",
    "        self.min_order = 0.002 # 최소 주문 수량\n",
    "        self.fee = 0.0005 # 거래 수수료\n",
    "        self.leverage = leverage # 레버리지\n",
    "        \n",
    "        # reset 포함\n",
    "        self.usdt_balance = usdt_balance # 초기 usdt 잔고\n",
    "        self.btc_size = btc_size # 포지션 수량\n",
    "        self.margin = 0 # 포지션 증거금\n",
    "        self.position = 2 # 포지션 {0:Long, 1:Short, 2:None}\n",
    "        self.order_price = 0 # 주문 금액\n",
    "        self.last_size_value = 0 # (평단가 계산에 필요)\n",
    "        self.current_avg_price = 0 # 현재 평단가\n",
    "        self.pnl = 0 # 미실현 손익\n",
    "        self.closing_pnl = 0 # 실현 손익\n",
    "        self.total_pnl = 0 # 누적 손익\n",
    "        self.total_fee = 0 # 누적 수수료\n",
    "        self.total_balance = 0 # 총 자산\n",
    "        self.action_history = pd.DataFrame(columns=['action'])\n",
    "        self.current_index = 0\n",
    "        pass\n",
    "\n",
    "    def reset(self): # 리셋 함수 \n",
    "        self.slice_df, self.obs_df, self.train_df = stablebaselineEnv.generate_random_data_slice(df, self.full_window_size, self.test_window_size) # 랜덤 위치로 slice된 차트 데이터 초기화\n",
    "        self.action_space = spaces.Discrete(4)  # 0: Long, 1: Short, 2: Close, 3: Hold\n",
    "        self.current_step = self.slice_df.tail(1)\n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"chart_data\": spaces.Box(low=0, high=np.inf, shape=(len(self.current_step.columns),), dtype=np.float32), # 차트 데이터\n",
    "            \"position\": spaces.Discrete(3),  # 포지션 {0:Long, 1:Short, 2:None}\n",
    "            \"action\": spaces.Discrete(4),  # 액션 {0:Long, 1:Short, 2:Close, 3:Hold}\n",
    "            \"current_price\": spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),  # 현재 가격\n",
    "            \"avg_price\": spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),  # 평균 진입 가격\n",
    "            \"pnl\": spaces.Box(low=-np.inf, high=np.inf, shape=(1,), dtype=np.float32),  # 미실현 손익\n",
    "            \"total_pnl\": spaces.Box(low=-np.inf, high=np.inf, shape=(1,), dtype=np.float32),  # 누적 손익\n",
    "            \"usdt_balance\": spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),  # USDT 잔고\n",
    "            \"size\": spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),  # 포지션 수량\n",
    "            \"margin\": spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),  # 사용 중인 마진\n",
    "            \"total_balance\": spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32)  # 총 자산\n",
    "        })\n",
    "\n",
    "        self.start_step = self.full_window_size\n",
    "        self.window_size = self.full_window_size\n",
    "        self.current_price = 0\n",
    "        self.usdt_balance = self.initial_usdt_balance # 초기 usdt 잔고\n",
    "        self.btc_size = 0 # 포지션 수량\n",
    "        self.margin = 0 # 포지션 증거금\n",
    "        self.position = 2 # 포지션 {0:Long, 1:Short, 2:None}\n",
    "        self.order_price = 0 # 주문 금액\n",
    "        self.last_size_value = 0 # (평단가 계산에 필요)\n",
    "        self.current_avg_price = 0 # 현재 평단가\n",
    "        self.pnl = 0 # 미실현 손익\n",
    "        self.closing_pnl = 0 # 실현 손익\n",
    "        self.total_pnl = 0 # 누적 손익\n",
    "        self.total_fee = 0 # 누적 수수료\n",
    "        self.total_balance = 0 # 총 자산\n",
    "        self.action_history = pd.DataFrame(columns=['action'])\n",
    "        self.current_index = 0\n",
    "        \n",
    "        # obs = {\n",
    "        #     \"chart_data\": self.current_step.values.flatten(),\n",
    "        #     \"position\": self.position,\n",
    "        #     \"action\": 3,  # Hold 액션으로 초기화\n",
    "        #     \"current_price\": self.current_price,\n",
    "        #     \"avg_price\": self.current_avg_price,\n",
    "        #     \"pnl\": self.pnl,\n",
    "        #     \"total_pnl\": self.total_pnl,\n",
    "        #     \"usdt_balance\": round(self.usdt_balance, 2),\n",
    "        #     \"size\": self.btc_size,\n",
    "        #     \"margin\": self.margin,\n",
    "        #     \"total_balance\": self.total_balance\n",
    "        # }\n",
    "        obs = {\n",
    "            \"chart_data\": self.current_step.values,  # 차원 조정: 2차원 배열로 변환\n",
    "            \"position\": np.array([self.position]),  # 차원 조정: 1차원 배열로 변환\n",
    "            \"action\": np.array([3]),  # Hold 액션으로 초기화, 차원 조정: 1차원 배열로 변환\n",
    "            \"current_price\": np.array([self.current_price]),  # 차원 조정: 1차원 배열로 변환\n",
    "            \"avg_price\": np.array([self.current_avg_price]),  # 차원 조정: 1차원 배열로 변환\n",
    "            \"pnl\": np.array([self.pnl]),  # 차원 조정: 1차원 배열로 변환\n",
    "            \"total_pnl\": np.array([self.total_pnl]),  # 차원 조정: 1차원 배열로 변환\n",
    "            \"usdt_balance\": np.array([round(self.usdt_balance, 2)]),  # 차원 조정: 1차원 배열로 변환\n",
    "            \"size\": np.array([self.btc_size]),  # 차원 조정: 1차원 배열로 변환\n",
    "            \"margin\": np.array([self.margin]),  # 차원 조정: 1차원 배열로 변환\n",
    "            \"total_balance\": np.array([self.total_balance])  # 차원 조정: 1차원 배열로 변환\n",
    "        }\n",
    "        \n",
    "        return obs\n",
    "        \n",
    "    def seed(self, seed=None):\n",
    "        np.random.seed(seed)\n",
    "        return [seed]\n",
    "    \n",
    "    # 나중에 수량지정을 위한 함수 (min_order부분만 바꾸면됌)\n",
    "    def cac_order_size(self): \n",
    "        order_size = self.min_order\n",
    "        return order_size\n",
    "    \n",
    "    # action을 수행할 수 있는 최소한의 조건 확인\n",
    "    def act_check(self, action):\n",
    "        required_margin = (self.cac_order_size() * self.current_price) / self.leverage\n",
    "        \n",
    "        if action == 0 or action == 1:\n",
    "            if self.position == action or self.position == 2 or self.position is None:\n",
    "                if self.usdt_balance > required_margin:\n",
    "                    return action\n",
    "                else:\n",
    "                    return 3\n",
    "            else:\n",
    "                if self.usdt_balance + self.margin + self.pnl > required_margin:\n",
    "                    return action\n",
    "                else:\n",
    "                    return 3\n",
    "        \n",
    "        elif action == 2:\n",
    "            if self.position == 0 or self.position == 1:\n",
    "                return 2\n",
    "            else:\n",
    "                return 3\n",
    "        \n",
    "        elif action == 3 or self.position is None:\n",
    "            return 3\n",
    "\n",
    "        \n",
    "\n",
    "    # 포지션 진입\n",
    "    def open_position(self, action):\n",
    "        order_size = self.cac_order_size()\n",
    "        required_margin = (order_size * self.current_price) / self.leverage\n",
    "        open_fee = order_size * self.current_price * self.fee\n",
    "        \n",
    "        self.usdt_balance -= required_margin + open_fee\n",
    "        self.btc_size += order_size\n",
    "        self.margin += required_margin\n",
    "        \n",
    "        self.order_price = order_size * self.current_price\n",
    "        self.current_avg_price = (self.order_price + self.last_size_value) / self.btc_size\n",
    "        self.last_size_value = self.btc_size * self.current_price\n",
    "                        \n",
    "        self.pnl = (1 if action == 0 else -1) * (\n",
    "            self.current_price - self.current_avg_price) * self.btc_size * self.leverage\n",
    "            \n",
    "        self.total_fee -= open_fee\n",
    "        self.total_balance = self.usdt_balance + self.margin\n",
    "        self.position = action\n",
    "        \n",
    "    def close_position(self):\n",
    "        closing_fee = self.btc_size * self.current_price * self.fee\n",
    "        closing_pnl = (1 if self.position == 0 else -1) * (\n",
    "            self.current_price - self.current_avg_price) * self.btc_size * self.leverage\n",
    "        \n",
    "        self.usdt_balance += self.margin + closing_pnl - closing_fee\n",
    "        self.total_fee -= closing_fee\n",
    "        self.total_pnl += closing_pnl\n",
    "        self.closing_pnl = closing_pnl\n",
    "        \n",
    "        self.btc_size = 0\n",
    "        self.margin = 0\n",
    "        self.pnl = 0\n",
    "        self.last_size_value = 0\n",
    "        \n",
    "        self.total_balance = self.usdt_balance + self.margin\n",
    "        self.position = 2\n",
    "\n",
    "    def act(self, action):\n",
    "        action = self.act_check(action)\n",
    "        if action == 0 or action == 1:  # Long or Short\n",
    "            if self.position == action or self.position == 2 or self.position is None:\n",
    "                self.open_position(action)\n",
    "            else:\n",
    "                self.close_position()\n",
    "                self.open_position(action)\n",
    "        \n",
    "        elif action == 2:  # Close\n",
    "            if self.position == 0 or self.position == 1:\n",
    "                self.close_position()\n",
    "                \n",
    "        \n",
    "        elif action == 3:  # Hold\n",
    "            if self.position == 0:  # Long\n",
    "                self.pnl = (self.current_price - self.current_avg_price) * self.btc_size * self.leverage\n",
    "            elif self.position == 1:  # Short\n",
    "                self.pnl = (self.current_avg_price - self.current_price) * self.btc_size * self.leverage\n",
    "            \n",
    "            self.total_balance = self.usdt_balance + self.margin\n",
    "        return action\n",
    "    \n",
    "    '''\n",
    "    액션 :\n",
    "        action : 0=Long, 1=Short, 2=Close, 3=Hold\n",
    "        position : 0=Long, 1=Short, 2=None\n",
    "        ex) (0.002*68000)/1=136, (0.002*68000)/2=68 필요 증거금 계산 예시 #\n",
    "        \n",
    "        return : self.position, self.acutal_action, self.pnl, self.closing_pnl, self.total_pnl, self.total_balance\n",
    "        \n",
    "        주문 수량은 일단 항상 최소 주문 금액으로 하겠습니다.\n",
    "        최소 수량으로 해도 0.002개 이고 1배율일 경우 증거금 136usdt 정도 들어갑니다.\n",
    "        \n",
    "        추후 수량이 커질시 미결손실 또한 고려해야함\n",
    "    ''' \n",
    "    \n",
    "    # df 데이터를 받아 full_window_size만큼 랜덤 위치로 잘라서 Obs_df와 train_df로 나눈 df를 반환해주는 함수\n",
    "    def generate_random_data_slice(df, full_window_size, test_window_size):\n",
    "        strat_index = np.random.randint(0, len(df) - full_window_size)\n",
    "        end_index = strat_index + full_window_size\n",
    "        obs_end = end_index - test_window_size\n",
    "        \n",
    "        slice_df = df[strat_index:end_index]\n",
    "        obs_df = df[strat_index:obs_end]\n",
    "        train_df = df[obs_end:end_index]\n",
    "        # slice_df : 전체 데이터에서 랜덤한 위치로 잘라낸 데이터\n",
    "        # obs_df : 전체 데이터중 현재 스텝의 이전 데이터로써 이미 알고있는 차트 데이터\n",
    "        # train_df : 전체 데이터중 현재 스텝의 이후 데이터로써 학습을 위한 차트 데이터\n",
    "        \n",
    "        return slice_df, obs_df, train_df\n",
    "    \n",
    "    # 다음 step과 가격을 가져옴\n",
    "    def next_obs(self): \n",
    "        row_to_move = self.train_df.iloc[0:1] # train_df의 첫 행을 가져옴\n",
    "        self.obs_df = pd.concat([self.obs_df, row_to_move]) # obs_df의 마지막 행에 train_df의 첫 행을 추가\n",
    "        self.train_df = self.train_df.drop(self.train_df.index[0]) # train_df의 첫 행을 제거 (메모리 절약을 위해)\n",
    "        self.current_step = self.obs_df.tail(1) # obs_df의 마지막 행을 현재 스텝으로 설정\n",
    "        self.current_price = round(random.uniform(self.current_step['Open'].iloc[-1], self.current_step['Close'].iloc[-1]), 2) # 현재 가격을 시가, 종가 사이 랜덤 값으로 결정\n",
    "\n",
    "    def calculate_reward(self):\n",
    "        reward = 0\n",
    "        if self.closing_pnl > 0:\n",
    "            reward += 2\n",
    "            \n",
    "        elif self.closing_pnl < 0:\n",
    "            reward -= 1\n",
    "            \n",
    "        self.closing_pnl = 0\n",
    "        return reward\n",
    "    \n",
    "    def step(self, action):\n",
    "        \n",
    "        self.next_obs() # 다음 obs를 가져옴\n",
    "        if (np.array(self.current_step) == None).all(): # 다음 훈련 데이터 없을 시 done = True로 변경 종료\n",
    "            done = True\n",
    "            return None, None, done, {}\n",
    "        \n",
    "        action = self.act(action) # action을 수행함.\n",
    "        reward = self.calculate_reward() # reward 계산\n",
    "        action_row = pd.DataFrame({'action': [action]}, index=[self.slice_df.index[self.current_index]]) \n",
    "        self.action_history = pd.concat([self.action_history, action_row]) # action_history에 action 추가\n",
    "        if self.total_balance < self.total_balance * 0.3:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        # obs = {\n",
    "        #     \"chart_data\": self.current_step.values.flatten(),\n",
    "        #     \"position\": self.position,\n",
    "        #     \"action\": action,\n",
    "        #     \"current_price\": self.current_price,\n",
    "        #     \"avg_price\": self.current_avg_price,\n",
    "        #     \"pnl\": self.pnl,\n",
    "        #     \"total_pnl\": self.total_pnl,\n",
    "        #     \"usdt_balance\": round(self.usdt_balance, 2),\n",
    "        #     \"size\": self.btc_size,\n",
    "        #     \"margin\": self.margin,\n",
    "        #     \"total_balance\": self.total_balance\n",
    "        # }\n",
    "        obs = {\n",
    "            \"chart_data\": self.current_step.values,  # 차원 조정: 2차원 배열로 변환\n",
    "            \"position\": np.array([self.position]),  # 차원 조정: 1차원 배열로 변환\n",
    "            \"action\": np.array([action]),  # Hold 액션으로 초기화, 차원 조정: 1차원 배열로 변환\n",
    "            \"current_price\": np.array([self.current_price]),  # 차원 조정: 1차원 배열로 변환\n",
    "            \"avg_price\": np.array([self.current_avg_price]),  # 차원 조정: 1차원 배열로 변환\n",
    "            \"pnl\": np.array([self.pnl]),  # 차원 조정: 1차원 배열로 변환\n",
    "            \"total_pnl\": np.array([self.total_pnl]),  # 차원 조정: 1차원 배열로 변환\n",
    "            \"usdt_balance\": np.array([round(self.usdt_balance, 2)]),  # 차원 조정: 1차원 배열로 변환\n",
    "            \"size\": np.array([self.btc_size]),  # 차원 조정: 1차원 배열로 변환\n",
    "            \"margin\": np.array([self.margin]),  # 차원 조정: 1차원 배열로 변환\n",
    "            \"total_balance\": np.array([self.total_balance])  # 차원 조정: 1차원 배열로 변환\n",
    "        }\n",
    "\n",
    "\n",
    "        return obs, reward, done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#self, df, full_window_size, test_window_size, usdt_balance=1000, btc_size=0, leverage=1\n",
    "full_window_size = 100\n",
    "test_window_size = 60\n",
    "usdt_balance = 1000\n",
    "btc_size = 0\n",
    "leverage = 1\n",
    "env = stablebaselineEnv(df, full_window_size, test_window_size, usdt_balance, btc_size, leverage)\n",
    "# env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 5)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.current_step.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'chart_data': array([4.709086e+04, 4.710040e+04, 4.703601e+04, 4.704219e+04,\n",
       "         2.842520e+01]),\n",
       "  'position': array([1]),\n",
       "  'action': array([1]),\n",
       "  'current_price': array([47061.4]),\n",
       "  'avg_price': array([47061.4]),\n",
       "  'pnl': array([-0.]),\n",
       "  'total_pnl': array([0]),\n",
       "  'usdt_balance': array([905.83]),\n",
       "  'size': array([0.002]),\n",
       "  'margin': array([94.1228]),\n",
       "  'total_balance': array([999.9529386])},\n",
       " 0,\n",
       " False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = 1\n",
    "obs, reward, done, _ = env.step(action)\n",
    "obs, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Dimension out of range (expected to be in range of [-1, 0], but got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[70], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m checkpoint_callback \u001b[38;5;241m=\u001b[39m CheckpointCallback(save_freq\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10000\u001b[39m, save_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./checkpoints/\u001b[39m\u001b[38;5;124m'\u001b[39m, name_prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrl_model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcheckpoint_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 학습된 모델 저장\u001b[39;00m\n\u001b[0;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mppo_stablebaseline\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:277\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 277\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:178\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;66;03m# Convert to pytorch tensor or to TensorDict\u001b[39;00m\n\u001b[0;32m    177\u001b[0m     obs_tensor \u001b[38;5;241m=\u001b[39m obs_as_tensor(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m--> 178\u001b[0m     actions, values, log_probs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    179\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m    181\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\policies.py:643\u001b[0m, in \u001b[0;36mActorCriticPolicy.forward\u001b[1;34m(self, obs, deterministic)\u001b[0m\n\u001b[0;32m    635\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    636\u001b[0m \u001b[38;5;124;03mForward pass in all the networks (actor and critic)\u001b[39;00m\n\u001b[0;32m    637\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    640\u001b[0m \u001b[38;5;124;03m:return: action, value and log probability of the action\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;66;03m# Preprocess the observation if needed\u001b[39;00m\n\u001b[1;32m--> 643\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor:\n\u001b[0;32m    645\u001b[0m     latent_pi, latent_vf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_extractor(features)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\policies.py:670\u001b[0m, in \u001b[0;36mActorCriticPolicy.extract_features\u001b[1;34m(self, obs, features_extractor)\u001b[0m\n\u001b[0;32m    661\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    662\u001b[0m \u001b[38;5;124;03mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[0;32m    663\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    667\u001b[0m \u001b[38;5;124;03m    features for the actor and the features for the critic.\u001b[39;00m\n\u001b[0;32m    668\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshare_features_extractor:\n\u001b[1;32m--> 670\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfeatures_extractor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    672\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m features_extractor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\policies.py:131\u001b[0m, in \u001b[0;36mBaseModel.extract_features\u001b[1;34m(self, obs, features_extractor)\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;124;03mPreprocess the observation if needed and extract features.\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;124;03m:return: The extracted features\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    130\u001b[0m preprocessed_obs \u001b[38;5;241m=\u001b[39m preprocess_obs(obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation_space, normalize_images\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnormalize_images)\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfeatures_extractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocessed_obs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\stable_baselines3\\common\\torch_layers.py:277\u001b[0m, in \u001b[0;36mCombinedExtractor.forward\u001b[1;34m(self, observations)\u001b[0m\n\u001b[0;32m    274\u001b[0m encoded_tensor_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, extractor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextractors\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m--> 277\u001b[0m     encoded_tensor_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mextractor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    278\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m th\u001b[38;5;241m.\u001b[39mcat(encoded_tensor_list, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\flatten.py:47\u001b[0m, in \u001b[0;36mFlatten.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend_dim\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: Dimension out of range (expected to be in range of [-1, 0], but got 1)"
     ]
    }
   ],
   "source": [
    "# 환경 생성\n",
    "env = stablebaselineEnv(df, full_window_size=200, test_window_size=120, usdt_balance=1000, btc_size=0, leverage=1)\n",
    "\n",
    "# 벡터화된 환경 생성 (병렬 학습을 위해)\n",
    "vec_env = make_vec_env(lambda: env, n_envs=4)\n",
    "\n",
    "# 모델 생성\n",
    "# model = PPO(\"MlpPolicy\", vec_env, verbose=1)\n",
    "model = PPO(\"MultiInputPolicy\", vec_env, verbose=1)\n",
    "\n",
    "# 체크포인트 콜백 설정\n",
    "checkpoint_callback = CheckpointCallback(save_freq=10000, save_path='./checkpoints/', name_prefix='rl_model')\n",
    "\n",
    "# 모델 학습\n",
    "model.learn(total_timesteps=1000, callback=checkpoint_callback)\n",
    "\n",
    "# 학습된 모델 저장\n",
    "model.save(\"ppo_stablebaseline\")\n",
    "\n",
    "# 학습된 모델 로드\n",
    "loaded_model = PPO.load(\"ppo_stablebaseline\")\n",
    "\n",
    "# 테스트\n",
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = loaded_model.predict(obs)\n",
    "    obs, rewards, done, info = env.step(action)\n",
    "    if done:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install shimmy>=0.2.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
