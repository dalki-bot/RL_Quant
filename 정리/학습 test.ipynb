{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import gym\n",
    "import stable_baselines3\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO,DQN,A2C\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.callbacks import CheckpointCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\yong\\Documents\\GitHub\\RL_Quant\\btctest.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stablebaselineEnv(gym.Env):\n",
    "    def __init__(self, df, full_window_size, test_window_size, usdt_balance, btc_size=0, leverage=1): \n",
    "        super(stablebaselineEnv, self).__init__()\n",
    "        self.df = df\n",
    "        # self.df['Volume'] = np.log(self.df['Volume'])\n",
    "\n",
    "        self.slice_df, self.obs_df, self.train_df = self.generate_random_data_slice(df, full_window_size, test_window_size)  # 랜덤 위치로 slice된 차트 데이터 초기화\n",
    "\n",
    "        # self.mean = np.mean(self.obs_df, axis=0)\n",
    "        # self.std = np.std(self.obs_df, axis=0)\n",
    "        # self.standard_slice_df, self.standard_obs_df, self.standard_train_df = stablebaselineEnv.standardzation(self.slice_df, self.obs_df, self.train_df, self.mean, self.std,mode=1)  # 정규화를 진행함. 모드 0,1 있음.\n",
    "\n",
    "        self.action_space = spaces.Discrete(4)  # 0: Long, 1: Short, 2: Close, 3: Hold\n",
    "        self.observation_space = spaces.Dict({\n",
    "            \"chart_data\": spaces.Box(low=0, high=np.inf, shape=self.obs_df.shape, dtype=np.float32), # 차트 데이터\n",
    "            \"position\": spaces.Discrete(3),  # 포지션 {0:Long, 1:Short, 2:None}\n",
    "            \"action\": spaces.Discrete(4),  # 액션 {0:Long, 1:Short, 2:Close, 3:Hold}\n",
    "            \"current_price\": spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),  # 현재 가격\n",
    "            \"avg_price\": spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),  # 평균 진입 가격\n",
    "            \"pnl\": spaces.Box(low=-np.inf, high=np.inf, shape=(1,), dtype=np.float32),  # 미실현 손익\n",
    "            \"total_pnl\": spaces.Box(low=-np.inf, high=np.inf, shape=(1,), dtype=np.float32),  # 누적 손익\n",
    "            \"usdt_balance\": spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),  # USDT 잔고\n",
    "            \"size\": spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),  # 포지션 수량\n",
    "            \"margin\": spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32),  # 사용 중인 마진\n",
    "            \"total_balance\": spaces.Box(low=0, high=np.inf, shape=(1,), dtype=np.float32)  # 총 자산\n",
    "        })\n",
    "        self.full_window_size = full_window_size\n",
    "        self.test_window_size = test_window_size\n",
    "        \n",
    "        # self.start_step = len(self.full_window_size - self.test_window_size)\n",
    "        self.current_step = self.obs_df.tail(1)\n",
    "        self.current_price = round(random.uniform(self.train_df['Open'].iloc[0], self.train_df['Close'].iloc[0]), 2) # 현재 가격을 시가, 종가 사이 랜덤 값으로 결정\n",
    "\n",
    "        # reset 미포함\n",
    "        self.initial_usdt_balance = usdt_balance # 초기 usdt 잔고\n",
    "        self.min_order = 0.002 # 최소 주문 수량\n",
    "        self.fee = 0.0005 # 거래 수수료\n",
    "        self.leverage = leverage # 레버리지\n",
    "        \n",
    "        # reset 포함\n",
    "        self.usdt_balance = usdt_balance # 초기 usdt 잔고\n",
    "        self.btc_size = btc_size # 포지션 수량\n",
    "        self.margin = 0 # 포지션 증거금\n",
    "        self.position = 2 # 포지션 {0:Long, 1:Short, 2:None}\n",
    "        self.order_price = 0 # 주문 금액\n",
    "        self.last_size_value = 0 # (평단가 계산에 필요)\n",
    "        self.current_avg_price = 0 # 현재 평단가\n",
    "        self.pnl = 0 # 미실현 손익\n",
    "        self.closing_pnl = 0 # 실현 손익\n",
    "        self.total_pnl = 0 # 누적 손익\n",
    "        self.total_fee = 0 # 누적 수수료\n",
    "        self.total_balance = 0 # 총 자산\n",
    "        # self.action_history = pd.DataFrame(columns=['action'])\n",
    "        self.current_index = 0\n",
    "\n",
    "\n",
    "    def reset(self): # 리셋 함수 \n",
    "        self.slice_df, self.obs_df, self.train_df = self.generate_random_data_slice(self.df, self.full_window_size, self.test_window_size) # 랜덤 위치로 slice된 차트 데이터 초기화\n",
    "        # self.mean = np.mean(self.obs_df, axis=0)\n",
    "        # self.std = np.std(self.obs_df, axis=0)\n",
    "        # self.standard_slice_df, self.standard_obs_df, self.standard_train_df = stablebaselineEnv.standardzation(self.slice_df, self.obs_df, self.train_df, self.mean, self.std,mode=1)  # 정규화를 진행함. 모드 0,1 있음.\n",
    "\n",
    "        # self.start_step = len(self.full_window_size - self.test_window_size)\n",
    "        self.current_step = self.obs_df.tail(1)\n",
    "        self.current_price = round(random.uniform(self.train_df.iloc[0]['Open'], self.train_df.iloc[0]['Close']), 2) # 현재 가격을 시가, 종가 사이 랜덤 값으로 결정\n",
    "\n",
    "        self.usdt_balance = self.initial_usdt_balance # 초기 usdt 잔고\n",
    "        self.btc_size = 0 # 포지션 수량\n",
    "        self.margin = 0 # 포지션 증거금\n",
    "        self.position = 2 # 포지션 {0:Long, 1:Short, 2:None}\n",
    "        self.order_price = 0 # 주문 금액\n",
    "        self.last_size_value = 0 # (평단가 계산에 필요)\n",
    "        self.current_avg_price = 0 # 현재 평단가\n",
    "        self.pnl = 0 # 미실현 손익\n",
    "        self.closing_pnl = 0 # 실현 손익\n",
    "        self.total_pnl = 0 # 누적 손익\n",
    "        self.total_fee = 0 # 누적 수수료\n",
    "        self.total_balance = 0 # 총 자산\n",
    "        # self.action_history = pd.DataFrame(columns=['action'])\n",
    "        self.current_index = 0\n",
    "\n",
    "        return self.get_obs() \n",
    "        \n",
    "    def seed(self, seed=None):\n",
    "        np.random.seed(seed)\n",
    "        return [seed]\n",
    "    \n",
    "    # 나중에 수량지정을 위한 함수 (min_order부분만 바꾸면됌)\n",
    "    def cac_order_size(self): \n",
    "        order_size = self.min_order\n",
    "        return order_size\n",
    "    \n",
    "    # action을 수행할 수 있는 최소한의 조건 확인\n",
    "    def act_check(self, action):\n",
    "        required_margin = (self.cac_order_size() * self.current_price) / self.leverage\n",
    "        \n",
    "        if action == 0 or action == 1:\n",
    "            if self.position == action or self.position == 2 or self.position is None:\n",
    "                if self.usdt_balance > required_margin:\n",
    "                    return action\n",
    "                else:\n",
    "                    return 3\n",
    "            else:\n",
    "                if self.usdt_balance + self.margin + self.pnl > required_margin:\n",
    "                    return action\n",
    "                else:\n",
    "                    return 3\n",
    "        \n",
    "        elif action == 2:\n",
    "            if self.position == 0 or self.position == 1:\n",
    "                return 2\n",
    "            else:\n",
    "                return 3\n",
    "        \n",
    "        elif action == 3 or self.position is None:\n",
    "            return 3\n",
    "\n",
    "    \n",
    "    # 포지션 진입\n",
    "    def open_position(self, action):\n",
    "        order_size = self.cac_order_size()\n",
    "        required_margin = (order_size * self.current_price) / self.leverage\n",
    "        open_fee = order_size * self.current_price * self.fee\n",
    "        \n",
    "        self.usdt_balance -= required_margin + open_fee\n",
    "        self.btc_size += order_size\n",
    "        self.margin += required_margin\n",
    "        \n",
    "        self.order_price = order_size * self.current_price\n",
    "        self.current_avg_price = (self.order_price + self.last_size_value) / self.btc_size\n",
    "        self.last_size_value = self.btc_size * self.current_price\n",
    "                        \n",
    "        self.pnl = (1 if action == 0 else -1) * (\n",
    "            self.current_price - self.current_avg_price) * self.btc_size * self.leverage\n",
    "            \n",
    "        self.total_fee -= open_fee\n",
    "        self.total_balance = self.usdt_balance + self.margin\n",
    "        self.position = action\n",
    "        \n",
    "    def close_position(self):\n",
    "        closing_fee = self.btc_size * self.current_price * self.fee\n",
    "        closing_pnl = (1 if self.position == 0 else -1) * (\n",
    "            self.current_price - self.current_avg_price) * self.btc_size * self.leverage\n",
    "        \n",
    "        self.usdt_balance += self.margin + closing_pnl - closing_fee\n",
    "        self.total_fee -= closing_fee\n",
    "        self.total_pnl += closing_pnl\n",
    "        self.closing_pnl = closing_pnl\n",
    "        \n",
    "        self.btc_size = 0\n",
    "        self.margin = 0\n",
    "        self.pnl = 0\n",
    "        self.last_size_value = 0\n",
    "        \n",
    "        self.total_balance = self.usdt_balance + self.margin\n",
    "        self.position = 2\n",
    "\n",
    "    def act(self, action):\n",
    "        action = self.act_check(action)\n",
    "        if action == 0 or action == 1:  # Long or Short\n",
    "            if self.position == action or self.position == 2 or self.position is None:\n",
    "                self.open_position(action)\n",
    "            else:\n",
    "                self.close_position()\n",
    "                self.open_position(action)\n",
    "        \n",
    "        elif action == 2:  # Close\n",
    "            if self.position == 0 or self.position == 1:\n",
    "                self.close_position()\n",
    "                \n",
    "        \n",
    "        elif action == 3:  # Hold\n",
    "            if self.position == 0:  # Long\n",
    "                self.pnl = (self.current_price - self.current_avg_price) * self.btc_size * self.leverage\n",
    "            elif self.position == 1:  # Short\n",
    "                self.pnl = (self.current_avg_price - self.current_price) * self.btc_size * self.leverage\n",
    "            \n",
    "            self.total_balance = self.usdt_balance + self.margin\n",
    "        return action\n",
    "    \n",
    "    '''\n",
    "    액션 :\n",
    "        action : 0=Long, 1=Short, 2=Close, 3=Hold\n",
    "        position : 0=Long, 1=Short, 2=None\n",
    "        ex) (0.002*68000)/1=136, (0.002*68000)/2=68 필요 증거금 계산 예시 #\n",
    "        \n",
    "        return : self.position, self.acutal_action, self.pnl, self.closing_pnl, self.total_pnl, self.total_balance\n",
    "        \n",
    "        주문 수량은 일단 항상 최소 주문 금액으로 하겠습니다.\n",
    "        최소 수량으로 해도 0.002개 이고 1배율일 경우 증거금 136usdt 정도 들어갑니다.\n",
    "        \n",
    "        추후 수량이 커질시 미결손실 또한 고려해야함\n",
    "    ''' \n",
    "    \n",
    "    # df 데이터를 받아 full_window_size만큼 랜덤 위치로 잘라서 Obs_df와 train_df로 나눈 df를 반환해주는 함수\n",
    "    def generate_random_data_slice(self, df, full_window_size, test_window_size):\n",
    "        strat_index = np.random.randint(0, len(df) - full_window_size)\n",
    "        end_index = strat_index + full_window_size\n",
    "        obs_end = end_index - test_window_size\n",
    "        \n",
    "        slice_df = df[strat_index:end_index]\n",
    "        obs_df = df[strat_index:obs_end]\n",
    "        train_df = df[obs_end:end_index]\n",
    "        # slice_df : 전체 데이터에서 랜덤한 위치로 잘라낸 데이터\n",
    "        # obs_df : 전체 데이터중 현재 스텝의 이전 데이터로써 이미 알고있는 차트 데이터\n",
    "        # train_df : 전체 데이터중 현재 스텝의 이후 데이터로써 학습을 위한 차트 데이터\n",
    "        \n",
    "        return slice_df, obs_df, train_df\n",
    "\n",
    "    def next_obs(self): \n",
    "        # row_to_move = self.train_df.iloc[0:1] # train_df의 첫 행을 가져옴\n",
    "        # self.obs_df = pd.concat([self.obs_df, row_to_move]) # obs_df의 마지막 행에 train_df의 첫 행을 추가\n",
    "        # self.obs_df = self.obs_df.drop(self.obs_df.index[0]) # obs_df의 첫 행을 제거 (메모리 절약을 위해)\n",
    "        # self.train_df = self.train_df.drop(self.train_df.index[0]) # train_df의 첫 행을 제거 (메모리 절약을 위해)\n",
    "        self.obs_df = \n",
    "        self.current_step = self.obs_df.tail(1) # obs_df의 마지막 행을 현재 스텝으로 설정\n",
    "        \n",
    "    def get_price(self):\n",
    "        open = self.slice_df.iloc[len(self.obs_df):len(self.obs_df)+1]['Open'].values[0]\n",
    "        close = self.slice_df.iloc[len(self.obs_df):len(self.obs_df)+1]['Close'].values[0]\n",
    "        self.current_price = round(random.uniform(open, close), 2) # 현재 가격을 시가, 종가 사이 랜덤 값으로 결정\n",
    "        \n",
    "    def calculate_reward(self):\n",
    "        reward = 0\n",
    "        if self.closing_pnl > 0:\n",
    "            reward += 2\n",
    "            \n",
    "        elif self.closing_pnl < 0:\n",
    "            reward -= 1\n",
    "            \n",
    "        self.closing_pnl = 0\n",
    "        return reward\n",
    "     # df 데이터를 받아 window_size + test_window_size만큼 랜덤 위치로 잘라서 자른 df를 반환해주는 함수\n",
    "\n",
    "    \n",
    "    def get_obs(self, action=3):\n",
    "        obs = {\n",
    "            \"chart_data\": self.obs_df.values,\n",
    "            \"position\": self.position,\n",
    "            \"action\": action,\n",
    "            \"current_price\": np.array([self.current_price]),\n",
    "            \"avg_price\": np.array([self.current_avg_price]),\n",
    "            \"pnl\": np.array([self.pnl]),\n",
    "            \"total_pnl\": np.array([self.total_pnl]),\n",
    "            \"usdt_balance\": np.array([self.usdt_balance]),\n",
    "            \"size\": np.array([self.btc_size]),\n",
    "            \"margin\": np.array([self.margin]),\n",
    "            \"total_balance\": np.array([self.total_balance])\n",
    "        }\n",
    "        return obs\n",
    "    \n",
    "    def step(self, action):\n",
    "        self.get_price() # 현재 가격을 가져옴\n",
    "        self.next_obs() # 다음 obs를 가져옴  \n",
    "        action = self.act(action) # action을 수행함.\n",
    "        reward = self.calculate_reward() # reward 계산\n",
    "        # action_row = pd.DataFrame({'action': [action]}, index=[self.slice_df.index[self.current_index]]) \n",
    "        # self.action_history = pd.concat([self.action_history, action_row]) # action_history에 action 추가\n",
    "        if self.total_balance < self.total_balance * 0.3:\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "        \n",
    "        return self.get_obs(action), reward, done, {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#self, df, full_window_size, test_window_size, usdt_balance=1000, btc_size=0, leverage=1\n",
    "full_window_size = 100\n",
    "test_window_size = 60\n",
    "usdt_balance = 1000\n",
    "btc_size = 0\n",
    "leverage = 1\n",
    "env = stablebaselineEnv(df, full_window_size, test_window_size, usdt_balance, btc_size, leverage)\n",
    "# env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47905.9"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.get_price()\n",
    "env.current_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'chart_data': array([[4.676000e+04, 4.680490e+04, 4.675000e+04, 4.679799e+04,\n",
       "         1.936307e+01],\n",
       "        [4.679799e+04, 4.681168e+04, 4.678602e+04, 4.678900e+04,\n",
       "         1.056628e+01],\n",
       "        [4.678900e+04, 4.681996e+04, 4.678137e+04, 4.681758e+04,\n",
       "         1.763267e+01],\n",
       "        [4.681792e+04, 4.683299e+04, 4.680000e+04, 4.680270e+04,\n",
       "         1.187380e+01],\n",
       "        [4.680271e+04, 4.683142e+04, 4.680270e+04, 4.682961e+04,\n",
       "         1.362539e+01],\n",
       "        [4.682961e+04, 4.686438e+04, 4.682526e+04, 4.684144e+04,\n",
       "         1.617609e+01],\n",
       "        [4.684144e+04, 4.686477e+04, 4.684144e+04, 4.685890e+04,\n",
       "         1.315325e+01],\n",
       "        [4.685890e+04, 4.688887e+04, 4.685210e+04, 4.687411e+04,\n",
       "         1.123275e+01],\n",
       "        [4.687412e+04, 4.687412e+04, 4.686022e+04, 4.686096e+04,\n",
       "         3.551150e+00],\n",
       "        [4.686097e+04, 4.686771e+04, 4.684000e+04, 4.684962e+04,\n",
       "         1.034033e+01],\n",
       "        [4.684962e+04, 4.686949e+04, 4.684961e+04, 4.686492e+04,\n",
       "         4.537200e+00],\n",
       "        [4.686492e+04, 4.687293e+04, 4.685369e+04, 4.685370e+04,\n",
       "         6.775310e+00],\n",
       "        [4.685370e+04, 4.690956e+04, 4.685369e+04, 4.690914e+04,\n",
       "         5.923360e+01],\n",
       "        [4.690914e+04, 4.691023e+04, 4.689561e+04, 4.689801e+04,\n",
       "         7.654270e+00],\n",
       "        [4.689801e+04, 4.689801e+04, 4.689176e+04, 4.689177e+04,\n",
       "         2.995170e+00],\n",
       "        [4.689176e+04, 4.689584e+04, 4.687706e+04, 4.689570e+04,\n",
       "         6.431020e+00],\n",
       "        [4.689302e+04, 4.689570e+04, 4.686884e+04, 4.688507e+04,\n",
       "         6.969550e+00],\n",
       "        [4.688507e+04, 4.688508e+04, 4.685050e+04, 4.685071e+04,\n",
       "         2.767090e+00],\n",
       "        [4.685050e+04, 4.685259e+04, 4.682962e+04, 4.683289e+04,\n",
       "         9.646040e+00],\n",
       "        [4.683289e+04, 4.683710e+04, 4.681843e+04, 4.681844e+04,\n",
       "         1.078345e+01],\n",
       "        [4.681844e+04, 4.685259e+04, 4.681843e+04, 4.682995e+04,\n",
       "         1.127340e+01],\n",
       "        [4.682996e+04, 4.687633e+04, 4.681972e+04, 4.687167e+04,\n",
       "         2.575209e+01],\n",
       "        [4.687167e+04, 4.687256e+04, 4.685810e+04, 4.685983e+04,\n",
       "         1.149392e+01],\n",
       "        [4.685983e+04, 4.686089e+04, 4.685333e+04, 4.685948e+04,\n",
       "         8.752430e+00],\n",
       "        [4.685948e+04, 4.687500e+04, 4.685690e+04, 4.687500e+04,\n",
       "         1.443060e+01],\n",
       "        [4.687499e+04, 4.688095e+04, 4.686811e+04, 4.687151e+04,\n",
       "         1.081358e+01],\n",
       "        [4.687151e+04, 4.687152e+04, 4.682982e+04, 4.684199e+04,\n",
       "         1.280748e+01],\n",
       "        [4.684197e+04, 4.686855e+04, 4.682984e+04, 4.685395e+04,\n",
       "         1.865312e+01],\n",
       "        [4.685394e+04, 4.685395e+04, 4.682179e+04, 4.683394e+04,\n",
       "         1.766583e+01],\n",
       "        [4.683393e+04, 4.684470e+04, 4.683157e+04, 4.684244e+04,\n",
       "         9.135070e+00],\n",
       "        [4.684244e+04, 4.687889e+04, 4.684187e+04, 4.687112e+04,\n",
       "         1.598382e+01],\n",
       "        [4.687112e+04, 4.687599e+04, 4.685728e+04, 4.686304e+04,\n",
       "         7.640550e+00],\n",
       "        [4.686304e+04, 4.686760e+04, 4.685728e+04, 4.686635e+04,\n",
       "         7.012250e+00],\n",
       "        [4.686634e+04, 4.691023e+04, 4.686476e+04, 4.689907e+04,\n",
       "         2.696136e+01],\n",
       "        [4.689907e+04, 4.691777e+04, 4.689638e+04, 4.690161e+04,\n",
       "         1.065182e+01],\n",
       "        [4.690161e+04, 4.690304e+04, 4.689292e+04, 4.689292e+04,\n",
       "         6.763990e+00],\n",
       "        [4.689292e+04, 4.692497e+04, 4.689292e+04, 4.691503e+04,\n",
       "         9.284330e+00],\n",
       "        [4.691503e+04, 4.691699e+04, 4.690303e+04, 4.690658e+04,\n",
       "         6.942940e+00],\n",
       "        [4.690658e+04, 4.691830e+04, 4.689430e+04, 4.689548e+04,\n",
       "         8.316680e+00],\n",
       "        [4.689548e+04, 4.691742e+04, 4.689078e+04, 4.690374e+04,\n",
       "         1.059640e+01]]),\n",
       " 'position': 2,\n",
       " 'action': 3,\n",
       " 'current_price': array([46917.64]),\n",
       " 'avg_price': array([0]),\n",
       " 'pnl': array([0]),\n",
       " 'total_pnl': array([0]),\n",
       " 'usdt_balance': array([1000]),\n",
       " 'size': array([0]),\n",
       " 'margin': array([0]),\n",
       " 'total_balance': array([0])}"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'chart_data': array([[4.728378e+04, 4.728378e+04, 4.727500e+04, 4.727500e+04,\n",
       "          2.933950e+00],\n",
       "         [4.727500e+04, 4.727527e+04, 4.725960e+04, 4.726421e+04,\n",
       "          3.663130e+00],\n",
       "         [4.726421e+04, 4.726421e+04, 4.725802e+04, 4.726136e+04,\n",
       "          3.556230e+00],\n",
       "         [4.726136e+04, 4.726136e+04, 4.725639e+04, 4.725828e+04,\n",
       "          4.744400e+00],\n",
       "         [4.725828e+04, 4.726347e+04, 4.721292e+04, 4.721294e+04,\n",
       "          8.297050e+00],\n",
       "         [4.721293e+04, 4.722695e+04, 4.719500e+04, 4.722669e+04,\n",
       "          1.006348e+01],\n",
       "         [4.722669e+04, 4.723000e+04, 4.720610e+04, 4.721766e+04,\n",
       "          8.063760e+00],\n",
       "         [4.721765e+04, 4.721766e+04, 4.720200e+04, 4.720363e+04,\n",
       "          5.389030e+00],\n",
       "         [4.720559e+04, 4.722673e+04, 4.720108e+04, 4.721586e+04,\n",
       "          4.692280e+00],\n",
       "         [4.721586e+04, 4.722238e+04, 4.721586e+04, 4.721685e+04,\n",
       "          3.722420e+00],\n",
       "         [4.721685e+04, 4.722267e+04, 4.721500e+04, 4.721501e+04,\n",
       "          4.224930e+00],\n",
       "         [4.721501e+04, 4.722000e+04, 4.721500e+04, 4.721871e+04,\n",
       "          4.635470e+00],\n",
       "         [4.721870e+04, 4.724299e+04, 4.721728e+04, 4.723911e+04,\n",
       "          5.631180e+00],\n",
       "         [4.723910e+04, 4.724300e+04, 4.722728e+04, 4.722728e+04,\n",
       "          3.299120e+00],\n",
       "         [4.722728e+04, 4.724000e+04, 4.722728e+04, 4.723778e+04,\n",
       "          3.569360e+00],\n",
       "         [4.723779e+04, 4.723779e+04, 4.722856e+04, 4.723227e+04,\n",
       "          2.492050e+00],\n",
       "         [4.723227e+04, 4.723778e+04, 4.723226e+04, 4.723777e+04,\n",
       "          2.320710e+00],\n",
       "         [4.723777e+04, 4.724292e+04, 4.723513e+04, 4.723550e+04,\n",
       "          5.397840e+00],\n",
       "         [4.723889e+04, 4.723912e+04, 4.723137e+04, 4.723720e+04,\n",
       "          4.817580e+00],\n",
       "         [4.723912e+04, 4.725319e+04, 4.723001e+04, 4.724775e+04,\n",
       "          1.089082e+01],\n",
       "         [4.724775e+04, 4.724977e+04, 4.711865e+04, 4.713073e+04,\n",
       "          6.877130e+01],\n",
       "         [4.713074e+04, 4.717587e+04, 4.712664e+04, 4.714905e+04,\n",
       "          3.493209e+01],\n",
       "         [4.714905e+04, 4.715135e+04, 4.707162e+04, 4.709998e+04,\n",
       "          3.229701e+01],\n",
       "         [4.709997e+04, 4.710002e+04, 4.702799e+04, 4.703487e+04,\n",
       "          2.214994e+01],\n",
       "         [4.703487e+04, 4.709999e+04, 4.703487e+04, 4.709058e+04,\n",
       "          1.811601e+01],\n",
       "         [4.709057e+04, 4.709583e+04, 4.701350e+04, 4.704349e+04,\n",
       "          1.312499e+01],\n",
       "         [4.704349e+04, 4.707210e+04, 4.704349e+04, 4.706900e+04,\n",
       "          8.515910e+00],\n",
       "         [4.706901e+04, 4.710504e+04, 4.706900e+04, 4.709747e+04,\n",
       "          1.538953e+01],\n",
       "         [4.709748e+04, 4.713047e+04, 4.709747e+04, 4.712126e+04,\n",
       "          8.395230e+00],\n",
       "         [4.712126e+04, 4.712687e+04, 4.706937e+04, 4.710713e+04,\n",
       "          1.733661e+01],\n",
       "         [4.710714e+04, 4.711700e+04, 4.709145e+04, 4.709835e+04,\n",
       "          3.565280e+00],\n",
       "         [4.709835e+04, 4.711119e+04, 4.709466e+04, 4.710120e+04,\n",
       "          4.372350e+00],\n",
       "         [4.710121e+04, 4.711692e+04, 4.709893e+04, 4.710837e+04,\n",
       "          4.483530e+00],\n",
       "         [4.710838e+04, 4.712880e+04, 4.710596e+04, 4.711823e+04,\n",
       "          1.184794e+01],\n",
       "         [4.711823e+04, 4.712997e+04, 4.711000e+04, 4.712615e+04,\n",
       "          5.238280e+00],\n",
       "         [4.712616e+04, 4.712618e+04, 4.708175e+04, 4.712153e+04,\n",
       "          1.059495e+01],\n",
       "         [4.712154e+04, 4.712970e+04, 4.710236e+04, 4.710818e+04,\n",
       "          5.389880e+00],\n",
       "         [4.710817e+04, 4.710818e+04, 4.708707e+04, 4.709552e+04,\n",
       "          6.451930e+00]]),\n",
       "  'position': 1,\n",
       "  'action': 1,\n",
       "  'current_price': array([47090.66]),\n",
       "  'avg_price': array([47092.435]),\n",
       "  'pnl': array([0.0071]),\n",
       "  'total_pnl': array([0]),\n",
       "  'usdt_balance': array([811.53607513]),\n",
       "  'size': array([0.004]),\n",
       "  'margin': array([188.36974]),\n",
       "  'total_balance': array([999.90581513])},\n",
       " 0,\n",
       " False)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = 1\n",
    "obs, reward, done, _ = env.step(action)\n",
    "obs, reward, done\n",
    "# env.next_obs()\n",
    "# env.slice_df,env.obs_df, env.train_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\yong\\Documents\\GitHub\\RL_Quant\\.conda\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (79,5) into shape (80,5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[201], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiInputPolicy\u001b[39m\u001b[38;5;124m\"\u001b[39m, vec_env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 모델 학습\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yong\\Documents\\GitHub\\RL_Quant\\.conda\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py:315\u001b[0m, in \u001b[0;36mPPO.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[0;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfPPO,\n\u001b[0;32m    308\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    313\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    314\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfPPO:\n\u001b[1;32m--> 315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    316\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yong\\Documents\\GitHub\\RL_Quant\\.conda\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:277\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[0;32m    274\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    276\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[1;32m--> 277\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    279\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[0;32m    280\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yong\\Documents\\GitHub\\RL_Quant\\.conda\\lib\\site-packages\\stable_baselines3\\common\\on_policy_algorithm.py:194\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[1;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[0;32m    192\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[1;32m--> 194\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\yong\\Documents\\GitHub\\RL_Quant\\.conda\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\yong\\Documents\\GitHub\\RL_Quant\\.conda\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:71\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mterminal_observation\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m obs\n\u001b[0;32m     70\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menvs[env_idx]\u001b[38;5;241m.\u001b[39mreset()\n\u001b[1;32m---> 71\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_save_obs\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obs_from_buf(), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews), np\u001b[38;5;241m.\u001b[39mcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones), deepcopy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos))\n",
      "File \u001b[1;32mc:\\Users\\yong\\Documents\\GitHub\\RL_Quant\\.conda\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:110\u001b[0m, in \u001b[0;36mDummyVecEnv._save_obs\u001b[1;34m(self, env_idx, obs)\u001b[0m\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_obs[key][env_idx] \u001b[38;5;241m=\u001b[39m obs\n\u001b[0;32m    109\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuf_obs\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m obs[key]\n",
      "\u001b[1;31mValueError\u001b[0m: could not broadcast input array from shape (79,5) into shape (80,5)"
     ]
    }
   ],
   "source": [
    "# 환경 생성\n",
    "df = pd.read_csv(r'C:\\Users\\yong\\Documents\\GitHub\\RL_Quant\\btctest.csv')\n",
    "env = stablebaselineEnv(df, full_window_size=200, test_window_size=120, usdt_balance=1000, btc_size=0, leverage=1)\n",
    "\n",
    "# 벡터화된 환경 생성 (병렬 학습을 위해)\n",
    "vec_env = make_vec_env(lambda: env, n_envs=4)\n",
    "\n",
    "# 모델 생성\n",
    "# model = PPO(\"MlpPolicy\", vec_env, verbose=1)\n",
    "model = PPO(\"MultiInputPolicy\", vec_env, verbose=1)\n",
    "# 모델 학습\n",
    "model.learn(total_timesteps=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install shimmy>=0.2.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
